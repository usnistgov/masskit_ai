checkpoint_in: null  # if set, the name of the checkpoint file to load to continue training
train:
  # spectral_library can be a file, e.g. ${oc.env:data_tandem}/human_hcd_tryp_good.pkl.gz
  # or an s3 bucket, s3://msdc-aiomics-data/human_hcd_tryp_good.pkl.gz
  # or http/https: https://msdc-aiomics-data.s3.amazonaws.com/human_hcd_tryp_good.pkl.gz
  spectral_library: ~/data/nist/ei/2023/rep_2023_path.parquet
  # the where setting is a list of tuples in string format, which corresponds to the tuple/list of tuples 
  # fed into the "filters" parameter of pyarrow.parquet.read_table()
  where: "[('set', '=', 'train'),('experimental_ri', '>', 0.0),('experimental_ri', '<=', 6280.0)]"
  num: null
  # if set, will log ids of training records to a file, one per epoch.
  log_ids: False
valid:
  spectral_library: ~/data/nist/ei/2023/rep_2023_path.parquet
  where: "[('experimental_ri', '>', 0.0),('experimental_ri', '<=', 6280.0)]"
  # number of datapoints in set. If null, compute
  num: null
test:
  spectral_library: ~/data/nist/ei/2023/rep_2023_path.parquet
  where: "[('experimental_ri', '>', 0.0),('experimental_ri', '<=', 6280.0)]"
  # number of datapoints in set. If null, compute
  num: null
