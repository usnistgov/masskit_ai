checkpoint_in: null  # if set, the name of the checkpoint file to load to continue training
train:
  # spectral_library can be a file, e.g. ${oc.env:data_tandem}/human_hcd_tryp_good.pkl.gz
  # or an s3 bucket, s3://msdc-aiomics-data/human_hcd_tryp_good.pkl.gz
  # or http/https: https://msdc-aiomics-data.s3.amazonaws.com/human_hcd_tryp_good.pkl.gz
  spectral_library: ${oc.env:HOME}/data/nist/ei/2020/mainlib_2020.parquet
  spectral_library_search: ${oc.env:HOME}/data/nist/ei/2020/mainlib_2020.parquet
  spectral_library_search_index: ${oc.env:HOME}/data/nist/ei/2020/mainlib_2020.ecfp4.tani.npy
  # spectral_library_search_index: ${oc.env:HOME}/data/nist/ei/2020/mainlib_2020.ecfp4.pynndescent
  # the where setting is a list of tuples in string format, which corresponds to the tuple/list of tuples 
  # fed into the "filters" parameter of pyarrow.parquet.read_table()
  where: "[('set', '=', 'train')]"
  where_search:
  # number of datapoints in set. If null, compute
  num: null
  # if set, will log ids of training records to a file, one per epoch.
  log_ids: False
valid:
  spectral_library: ${oc.env:HOME}/data/nist/ei/2020/replib_2020.parquet
  spectral_library_search: ${oc.env:HOME}/data/nist/ei/2020/mainlib_2020.parquet
  spectral_library_search_index: ${oc.env:HOME}/data/nist/ei/2020/mainlib_2020.ecfp4.tani.npy
  where: "[('set', '=', 'test')]"
  where_search:
  # number of datapoints in set. If null, compute
  num: null
test:
  spectral_library: ${oc.env:HOME}/data/nist/ei/2020/replib_2020.parquet
  spectral_library_search: ${oc.env:HOME}/data/nist/ei/2020/mainlib_2020.parquet
  spectral_library_search_index: ${oc.env:HOME}/data/nist/ei/2020/mainlib_2020.ecfp4.tani.npy
  where: "[('set', '=', 'test')]"
  where_search:
  # number of datapoints in set. If null, compute
  num: null
