# @package _group_
# used to place this config under a dictionary that matches the directory structure.  must be first line

# what type of spectral library are we using?  Defined in base_library.py
lib_type: TandemPepLib
checkpoint_in: null  # if set, the name of the checkpoint file to load to continue training
train:
  # spectral_library can be a file, e.g. ${oc.env:data_tandem}/human_hcd_tryp_good.pkl.gz
  # or an s3 bucket, s3://msdc-aiomics-data/human_hcd_tryp_good.pkl.gz
  # or http/https: https://msdc-aiomics-data.s3.amazonaws.com/human_hcd_tryp_good.pkl.gz
  spectral_library: ${oc.env:HOME}/data/nist/aiomics/take_two/original/training.parquet
  # spectral_library: https://msdc-aiomics-data.s3.amazonaws.com/2021-05-24_00_HmAll.db
  # the where setting is a list of tuples in string format, which corresponds to the tuple/list of tuples 
  # fed into the "filters" parameter of pyarrow.parquet.read_table()
  where: "[('peptide_len', '<', 41)]"
  # number of datapoints in set. If null, compute
  num: null
  # if set, will log ids of training records to a file, one per epoch.
  log_ids: False
valid:
  spectral_library: ${oc.env:HOME}/data/nist/aiomics/take_two/original/validation.parquet
  # spectral_library: https://msdc-aiomics-data.s3.amazonaws.com/2021-07-01_01_ChoLibUniq.db
  where: "[('peptide_len', '<', 41)]"
  # number of datapoints in set. If null, compute
  num: null
test:
  spectral_library: ${oc.env:HOME}/data/nist/aiomics/take_two/original/test.parquet
  where: "[('peptide_len', '<', 41)]"
  # number of datapoints in set. If null, compute
  num: null
